{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Holdout, Cross-validation and t-test\n",
    "\n",
    "Using the `iris` data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Holdout, Cross-validation and t-test\n",
    "\n",
    "Using the `iris` data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Train\" and evaluate\n",
    "\n",
    "Build a model for 3NN using tht `KNeighborsClassifier` from SciKitLearn.\n",
    "Measure the accuracy on the training data. This is an over optimistic estimate of accuracy. Not to be trusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "model.fit(X, y)\n",
    "y_model = model.predict(X)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y, y_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Holdout\n",
    "\n",
    "With holdout we split the data set in train and test sets. The evaluation will tend to have worse results. But not necessarily always."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# split the data with 50% in each set\n",
    "# parameter random_state=0 defines the seed\n",
    "X1, X2, y1, y2 = train_test_split(X, y, train_size=0.9)\n",
    "\n",
    "# fit the model on one set of data\n",
    "model.fit(X1, y1)\n",
    "\n",
    "# evaluate the model on the second set of data\n",
    "y2_model = model.predict(X2)\n",
    "accuracy_score(y2, y2_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation (2 fold, from scratch)\n",
    "\n",
    "A 2-fold cross validation from scratch. Split data in two equally sized folds. Train with one and test on the other and switch roles. Now you have two accuracy values that you can also average to obtain a more robust estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9333333333333333, 0.96)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2-fold Cross Validation\n",
    "X1, X2, y1, y2 = train_test_split(X, y, train_size=0.5)\n",
    "y2_model = model.fit(X1, y1).predict(X2)\n",
    "y1_model = model.fit(X2, y2).predict(X1)\n",
    "accuracy_score(y1, y1_model), accuracy_score(y2, y2_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-fold Cross Validation\n",
    "\n",
    "Method `cross_val_score` applies CV to a data set using a given model (in fact, using an algorithm). The `cv` argument can define the number of folds we want. The output is an array of scores (accuracy by default, but we can calculate other scores). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96666667, 0.96666667, 0.93333333, 0.96666667, 1.        ])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores=cross_val_score(model, X, y, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean and standard deviaton of the values of accuracy give us information about the random variable $Accuracy$ for this particular dataset. We can also plot these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.96, 0.024944382578492935)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean(), scores.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare 1NN and 5NN\n",
    "\n",
    "Perform 10 fold cross validation with 1NN and 5NN. Observe the two samples of ten accuracy values. Look at the means. The score of 5NN will tend to be better because 1NN tends to overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores 1: [1.         0.93333333 1.         0.93333333 0.86666667 1.\n",
      " 0.86666667 1.         1.         1.        ]\n",
      "scores 5: [1.         0.93333333 1.         1.         0.86666667 0.93333333\n",
      " 0.93333333 1.         1.         1.        ]\n",
      "mean 1: 0.96\n",
      "mean 5: 0.9666666666666668\n"
     ]
    }
   ],
   "source": [
    "# compare 1-NN with 5-NN on 10 fold CV\n",
    "import numpy as np\n",
    "\n",
    "model_1 = KNeighborsClassifier(n_neighbors=1)\n",
    "model_5 = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "scores_1=cross_val_score(model_1, X, y, cv=10)\n",
    "scores_5=cross_val_score(model_5, X, y, cv=10)\n",
    "print(\"scores 1:\",scores_1)\n",
    "print(\"scores 5:\",scores_5)\n",
    "print(\"mean 1:\",np.mean(scores_1))\n",
    "print(\"mean 5:\",np.mean(scores_5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-test\n",
    "\n",
    "But are the scores for 1NN and 5NN really different? Let's perform a statistical test, a $t-test$. This assumes that the accuracy has a $t-student$ distribution (no reasons to doubt that) and that the values of each sample are independent. This last assumption does not hold for the training sets. only for the test sets. However, we can still learn something from the result. But it is still optimistic. But less optimistic.  \n",
    "\n",
    "The differen between 1NN and 5NN is not significant according to this particular experiment. Note that different experiments may give different results. But the more significant the difference, the more stable the results are.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores 1: [1.         0.93333333 1.         0.93333333 0.86666667 1.\n",
      " 0.86666667 1.         1.         1.        ]\n",
      "scores 5: [1.         0.93333333 1.         1.         0.86666667 0.93333333\n",
      " 0.93333333 1.         1.         1.        ]\n",
      "mean 1: 0.96\n",
      "mean 5: 0.9666666666666668\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=-0.5570860145311556, pvalue=0.5910512317836047)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "model_5 = KNeighborsClassifier(n_neighbors=5)\n",
    "scores_5=cross_val_score(model_5, X, y, cv=10)\n",
    "print(\"scores 1:\",scores_1)\n",
    "print(\"scores 5:\",scores_5)\n",
    "print(\"mean 1:\",np.mean(scores_1))\n",
    "print(\"mean 5:\",np.mean(scores_5))\n",
    "stats.ttest_rel(scores_1, scores_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100NN will very likely give a poor result since it tends to give the majority class and is affcted by sampling in a way that is not easy to predict. So, compared with 1NN,for a level of significance $\\alpha=0.05$, it tends to give a significant difference ($p-value < 0.05$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores 100: [0.66666667 0.66666667 0.66666667 0.66666667 0.66666667 0.66666667\n",
      " 0.66666667 0.66666667 0.66666667 0.6       ]\n",
      "scores 5: [1.         0.93333333 1.         1.         0.86666667 0.93333333\n",
      " 0.93333333 1.         1.         1.        ]\n",
      "mean 100: 0.6599999999999999\n",
      "mean 5: 0.9666666666666668\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=-17.250000000000007, pvalue=3.332867923402167e-08)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "model_100 = KNeighborsClassifier(n_neighbors=100)\n",
    "scores_100=cross_val_score(model_100, X, y, cv=10)\n",
    "print(\"scores 100:\",scores_100)\n",
    "print(\"scores 5:\",scores_5)\n",
    "print(\"mean 100:\",np.mean(scores_100))\n",
    "print(\"mean 5:\",np.mean(scores_5))\n",
    "stats.ttest_rel(scores_100, scores_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle\n",
    "\n",
    "Cross-validation may work better if the data is shuffled first. It may not be needed, but it never hurts in terms of results. It can be computationally heavy though. It is at least $O(n)$. The `cross_val_score` method can take a specific split as an argument instead of the number of folds. When the number $k$ of folds is given, it splits the data in $k$ folds starting with the first example and following the order of the examples as they are in the data set. If asplit is given to the `cv` argument, the examples will be split according to what is defined in the split. This is how you use Shuffling in this case. From the data set you shuffle (reorder randomly) the examples' indexes and then split them sequentially.\n",
    "\n",
    "Let's see an example, suppose you have the examples $<1,2,3,4,5,6>$ and $k$ is 3. Your folds would be:\n",
    "\n",
    "- fold 1 = $<1,2>$\n",
    "- fold 2 = $<3,4>$\n",
    "- fold 3 = $<5,6>$\n",
    "\n",
    "If you shuffle first, you first reorder randomly as is $<3,5,2,1,6,4>$ and the split.\n",
    "\n",
    "- fold 1 = $<3,5>$\n",
    "- fold 2 = $<2,1>$\n",
    "- fold 3 = $<6,4>$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores 1: [1.         0.93333333 0.86666667 0.93333333 1.         1.\n",
      " 0.93333333 0.93333333 0.93333333 0.93333333]\n",
      "scores 5: [1.         0.93333333 0.93333333 0.93333333 1.         1.\n",
      " 0.93333333 0.93333333 0.93333333 1.        ]\n",
      "mean 1: 0.9466666666666667\n",
      "mean 5: 0.96\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=-1.5, pvalue=0.16785065605707486)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "n_samples = X.shape[0]\n",
    "cv = ShuffleSplit(n_splits=10, random_state=3)\n",
    "scores_1=cross_val_score(model_1, X, y, cv=cv)\n",
    "scores_5=cross_val_score(model_5, X, y, cv=cv)\n",
    "print(\"scores 1:\",scores_1)\n",
    "print(\"scores 5:\",scores_5)\n",
    "print(\"mean 1:\",np.mean(scores_1))\n",
    "print(\"mean 5:\",np.mean(scores_5))\n",
    "stats.ttest_rel(scores_1, scores_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can now make many experiments like comparing 5NN to 50NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores 50: [1.         1.         0.93333333 0.93333333 1.         1.\n",
      " 0.93333333 0.8        0.8        0.86666667]\n",
      "scores 5: [1.         0.93333333 0.93333333 0.93333333 1.         1.\n",
      " 0.93333333 0.93333333 0.93333333 1.        ]\n",
      "mean 50: 0.9266666666666667\n",
      "mean 5: 0.96\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=-1.4638501094227998, pvalue=0.17726770250560825)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_50 = KNeighborsClassifier(n_neighbors=50)\n",
    "scores_50=cross_val_score(model_50, X, y, cv=cv)\n",
    "print(\"scores 50:\",scores_50)\n",
    "print(\"scores 5:\",scores_5)\n",
    "print(\"mean 50:\",np.mean(scores_50))\n",
    "print(\"mean 5:\",np.mean(scores_5))\n",
    "stats.ttest_rel(scores_50, scores_5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
